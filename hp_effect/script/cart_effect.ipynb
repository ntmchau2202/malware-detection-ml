!pip install tensorflow_decision_forests==0.2.4
!pip install tensorflow-addons

from threading import Thread

import tensorflow as tf
import tensorflow_decision_forests as tfdf
import tensorflow_addons as tfa
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split

LABEL = 'legitimate'
classes = None

def load_csv(path):
  dataset_df = pd.read_csv(path, sep='|')
  dataset_df = dataset_df.drop(['Name', 'md5'], axis=1)
  classes = dataset_df[LABEL].unique().tolist()
  dataset_df[LABEL] = dataset_df[LABEL].map(classes.index) 
  return dataset_df

def cal_stat(dataset):
  neg, pos = np.bincount(dataset[LABEL])
  total = neg + pos 
  print('Examples:\n    Total: {}\n    Positive: {} ({:.2f}% of total)\n'.format(total, pos, 100 * pos / total))

def split_dataset(dataset, test_ratio=0.3):
  train_ds, test_ds = train_test_split(dataset, test_size=test_ratio)
  actual_train_ds, validate_ds = train_test_split(train_ds, test_size=test_ratio)
  return actual_train_ds, validate_ds, test_ds

def train_with_depth(X, Y, validateSet, testSet, maxDepth=5, metrics=['accuracy']):
  print('Training for depth=', maxDepth)
  model = tfdf.keras.CartModel(max_depth=maxDepth)
  model.compile(metrics=metrics)
  evaluation = model.fit(x=X, y=Y, batch_size=1000, verbose=0, validation_data=(validateSet, classes))
  test = model.evaluate(testSet, return_dict=True)
  return evaluation.history, test

def train_with_min_examples(X, Y, validateSet, testSet, minEx=10, metrics=['accuracry']):
  print('Training for min_examples=', minEx)
  model = tfdf.keras.CartModel(min_examples=minEx)
  model.compile(metrics=metrics)
  evaluation = model.fit(x=X, y=Y, batch_size=1000, verbose=0, validation_data=(validateSet, classes))
  test = model.evaluate(testSet, return_dict=True)
  return evaluation.history, test 

def iterate_depths(X, Y, validateSet, testSet, min=3, max=300, metrics=['accuracy'], depthResult=[]):
  for i in range(min, max+1, 1):
    evaluation, test = train_with_depth(X, Y, validateSet, testSet, i, metrics)
    depthResult.append({'depth': i, 'evaluation': evaluation.items(), 'test': test})
  
def iterate_min_examples(X, Y, validateSet, testSet, min=10, max=1000, metrics=['accuracry'], minExResult=[]):
  for i in range(min, max+1, 1):
    evaluation, test = train_with_min_examples(X, Y, validateSet, testSet, i, metrics)
    minExResult.append({'min_examples': i, 'evaluation': evaluation.items(), 'test': test})

linkFile = 'https://raw.githubusercontent.com/Te-k/malware-classification/master/data.csv'
deviceName = tf.test.gpu_device_name()

with tf.device(deviceName):
  dataset_df = load_csv(linkFile)

  train_ds_pd, validate_ds_pd, test_ds_pd = split_dataset(dataset_df, test_ratio=0.5)

  train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=LABEL, batch_size=1000)
  validate_ds = tfdf.keras.pd_dataframe_to_tf_dataset(validate_ds_pd, label=LABEL, batch_size=1000)
  test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_ds_pd, label=LABEL, batch_size=1000)

  cal_stat(train_ds_pd)
  cal_stat(validate_ds_pd)
  cal_stat(test_ds_pd)

  depthResults=[]
  minExResults=[]

  METRICS=['accuracy', tf.keras.metrics.Precision(name='precision'), tf.keras.metrics.Recall(name='recall'), tfa.metrics.F1Score(name='f1', num_classes=2, average="micro", threshold=0.9)]
  
  depthThread = Thread(target=iterate_depths, args=(train_ds, classes, validate_ds, test_ds, 3, 50, METRICS, depthResults))
  depthThread.start()
  minExThread = Thread(target=iterate_min_examples, args=(train_ds, classes, validate_ds, test_ds, 10, 300, METRICS, minExResults))
  minExThread.start()

  depthThread.join()
  minExThread.join()

  for i in range(len(depthResults)):
    print(depthResults[i])

  for i in range(len(minExResults)):
    print(minExResults[i])



